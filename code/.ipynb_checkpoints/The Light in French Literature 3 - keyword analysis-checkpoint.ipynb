{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d75c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36832a20",
   "metadata": {},
   "source": [
    "# The Light in French Literature 2 - keyword analysis\n",
    "## - The use of lighting technologies and sensations\n",
    "Which writers make the most and least use of sensational words when writting about lighting technologies?\n",
    "\n",
    "- how likely is it that a lighting technology is mentioned in a sentens containing “sensational vocabulary”?\n",
    "- how many lighting technology sentences are there?\n",
    "- how many of them contain sensational vocab?\n",
    "\n",
    "    1. split text in sentencens\n",
    "    2. count sentencens\n",
    "    3. count sentencens with lighting technology\n",
    "    4. count sentencens with lighting technology containing “sensational vocabulary”\n",
    "    5. caculate ratio of total sentencens and sentencens with lighting technology containing “sensational vocabulary”\n",
    "    6. caculate ratio of sentencens with lighting technology and sentencens with lighting technology containing “sensational vocabulary”\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e911468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d73f3",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "- Data is stored in a dataframe\n",
    "- in a function we detect presens of keywords in paragraphs. To do this we split the text into paragraphs and check then one by for a keyword. If a keyword is detected in a paragraph we do not continue to search for other keywords in the same paragraph. We just register, that a keyword is found in a paragraph and moves on to the next paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1224ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path.cwd() / '../data/csv_files' # path of files to be found\n",
    "csv_files = os.listdir(input_dir)\n",
    "print (f'The file name is {csv_files[-1]}')\n",
    "df = pd.read_csv(input_dir / csv_files[-1], sep='|')\n",
    "\n",
    "\n",
    "\n",
    "# split text in paragraphs and count paragraphs\n",
    "def count_sentences(text):\n",
    "    sent = text.split('.')\n",
    "    sent = [s.strip() for s in sent]\n",
    "    return len(sent)\n",
    "\n",
    "print ('\\n\\nCount paragraphs:\\n')\n",
    "df['count_paragraphs'] = df['text'].progress_apply(lambda text : count_sentences(text))\n",
    "\n",
    "\n",
    "#### Read two lists of keywords - technology and emotion keyowrds ####\n",
    "\n",
    "# path to keyword lists directory \n",
    "input_dir = Path.cwd() / '../data/key_word_lists' \n",
    "\n",
    "\n",
    "# get the tech words\n",
    "key_word_file_name = 'technology_list.txt'\n",
    "with open(input_dir / key_word_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "    tech_key_words = file.read().split('\\n')\n",
    "    \n",
    "# get the emo words    \n",
    "key_word_file_name = 'sensation_list.txt'\n",
    "with open(input_dir / key_word_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "    emo_key_words = file.read().split('\\n')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "### Build function to do the teck key word counting\n",
    "def count_kw(text, key_word_list):\n",
    "    text = text.lower()\n",
    "    sentencens = text.split('.')\n",
    "    list_of_sents = [s.strip() for s in sentences]\n",
    "    \n",
    "    count = 0\n",
    "    # take paragraphs one by one\n",
    "    for sent in list_of_sents:\n",
    "        # take every word in the list of keywords\n",
    "        for key_word in key_word_list:\n",
    "            # if a keyword is in the paragraph return boolean\n",
    "            if re.search(key_word, sent):\n",
    "                # then add one to the counter \n",
    "                count = count + 1\n",
    "                # and then break out and return to the beginning of the loop \n",
    "                break\n",
    "    return count\n",
    "\n",
    "def count_kw_in_kw_sent(text, key_word_list1, key_word_list2):\n",
    "    text = text.lower()\n",
    "    sentences = text.split('.')\n",
    "    list_of_sents = [s.strip() for s in sentences]\n",
    "    \n",
    "    count = 0\n",
    "    # take paragraphs one by one\n",
    "    for sent in list_of_sents:\n",
    "        \n",
    "        # take every word in the list of tech words\n",
    "        for key_word in key_word_list1:\n",
    "            # if a word from the list is in the paragraph\n",
    "            if re.search(key_word, sent):\n",
    "                for key_word in key_word_list2:\n",
    "                    if key_word in sent:\n",
    "                        # then add one to the counter \n",
    "                        count = count + 1\n",
    "                        # and then break out and return to the beginning of the loop \n",
    "                        break\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "######### Count keyword in paragraphs ##### \n",
    "\n",
    "print ('\\n\\nCount paragraphs with tech keywords:\\n')    \n",
    "df['p_lightning_kw'] = df['text'].progress_apply(lambda text : count_kw(text, tech_key_words))\n",
    "\n",
    "######### Count paragraphs with lighting technology containing “emotion vocabulary”\n",
    "print ('\\n\\nCount tech paragraphs that holds sensation keywords:\\n') \n",
    "df['p_lightning_emotion_kw'] = df['text'].progress_apply(lambda text : count_kw_in_kw_sent(text, tech_key_words, emo_key_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relative data\n",
    "new_df = df.copy()\n",
    "new_df['lightning technology paragraphs share of all paragraphs'] = new_df['p_lightning_kw'] / new_df['count_paragraphs'] \n",
    "new_df['emo and lightning technology paragraph share of all paragraphs'] = new_df['p_lightning_emotion_kw'] / new_df['count_paragraphs'] \n",
    "new_df['emo and lightning technology paragraph share of lightning technology paragraph'] = new_df['p_lightning_emotion_kw'] / new_df['p_lightning_kw']\n",
    "\n",
    "new_df = new_df.iloc[:, [0, 1,2,3,6,7,8,9,10]]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = new_df.index + 1\n",
    "y_var = 'emo and lightning technology paragraph share of all paragraphs'\n",
    "\n",
    "\n",
    "fig = px.bar(new_df.sort_values(by=y_var, ascending=False), \n",
    "            x = x_var, \n",
    "            y = y_var,\n",
    "            hover_data=['author','title', 'year', 'emo and lightning technology paragraph share of all paragraphs'],\n",
    "            title= 'Relative frequency of paragraphs')\n",
    "             \n",
    "# Update x-axis label\n",
    "fig.update_xaxes(title_text='Document in chronological order')\n",
    "\n",
    "# Update y-axis label\n",
    "fig.update_yaxes(title_text='Relative frequence') \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as io\n",
    "\n",
    "html_snippet_start = '<!DOCTYPE html> <html> <head> <title>Title</title> </head> <body>' \n",
    "html_snippet_end = ' </body></html> '\n",
    "\n",
    "html_as_string = io.to_html(fig, full_html=False)\n",
    "\n",
    "vis_in_html = html_snippet_start + html_as_string + html_snippet_end\n",
    "\n",
    "of = open(r'C:\\Users\\lakj\\Lighting in French Literature\\visualisations\\emo_in_light_para2.htm', 'w', encoding='utf-8-sig')\n",
    "of.write(vis_in_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2655a",
   "metadata": {},
   "source": [
    "# Keyword in context - or find a text snippet based on keywords and a range\n",
    "\n",
    "We want to find a word for example 'lumière' as well as words that are related to the word, and we have to have some context because we are actually interested in pointing down the text and seeing exactly how lumière is used.\n",
    "\n",
    "For this we need to use \\w. because it gives us more word characters and {30} checks that we get 30 word characters before we hit the letters lumière. \\b in front of lumière searches so that we only find words that begin with lumière and not words where lumière is part of the word, e.g. looking. After lumière, \\w.{30} searches for another 30 word characters.\n",
    "\n",
    "The pipe , | , means 'or' and alow us to get more than one word in the same search.\n",
    "\n",
    "Below I choose to look for contexts in texts of the author Balzac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c88a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df[df['author'] == 'Balzac']['clean_text'])\n",
    "import re\n",
    "context = re.findall(r'.{0,50}\\blampe.{0,40}|.{0,50}\\blustre.{0,40}', text)\n",
    "context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
