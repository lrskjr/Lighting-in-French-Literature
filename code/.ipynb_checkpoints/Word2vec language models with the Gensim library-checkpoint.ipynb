{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b55991d",
   "metadata": {},
   "source": [
    "# Build a Word2vec language models with the Gensim library\n",
    "\n",
    "Word2Vec is an algorithm that learns relationships between words using large amounts of text. The Word2Vec algorithm produces a language model where words with similar meanings based on context are close together and words with different meanings based on context are far apart. For example, Copenhagen and Denmark would be close together, while Copenhagen and cheese would be relatively far apart.\n",
    "\n",
    "Word2vec models can thus be used to find words that are similar in meaning and syntactic position and that have a common relationship.\n",
    "\n",
    "To build the Word2vec models, you can the library Gensim, which stands for generating similarities. Building the models is a labor-intensive process that takes many hours, so once the model is built, it is a good idea to save it for later use. Documentation for and description of how models are built and saved can be found on this page: https://radimrehurek.com/gensim/auto_examples/index.html\n",
    "\n",
    "Below we'll build a model of the corpus for French literature. One can debate whether it is responsible to build a model from novels from a wide year span, or whether a division into subsets would make more sense. For example would this model not take into account the historical and cultural changes of terms through the period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\lakj\\\\Love lighting in French Literature\\\\data')\n",
    "\n",
    "df = pd.read_csv('text_data230722.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a GenSim language model\n",
    "\n",
    "#Sources:\n",
    "## https://radimrehurek.com/gensim/auto_examples/index.html#documentation\n",
    "\n",
    "## https://stackabuse.com/implementing-word2vec-with-gensim-library-in-python/\n",
    "\n",
    "## https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "def build_w2v_model(clean_text):\n",
    "    \n",
    "    # data preperation\n",
    "    \n",
    "    ## split the text into sentences using the sent_tokenizer of the nltk library\n",
    "    sent_list = nltk.sent_tokenize(clean_text) \n",
    "    \n",
    "    ## split each sentence into list of words using the nltk word_tokenizer\n",
    "    tok_lists = [nltk.word_tokenize(sent) for sent in sent_list]\n",
    "\n",
    "\n",
    "    ### filter for the shortest words. Here this is words equal to a lenght of 1\n",
    "    tok_lists = [w for w in tok_lists if len(w) >=1]\n",
    "\n",
    "\n",
    "    # Build the W2V model\n",
    "    ## The value of min_count does so that only words that appears at least the value are included\n",
    "    \n",
    "    # w2v model basered on word lists\n",
    "    word2vec_tokens = Word2Vec(tok_lists, min_count=4)\n",
    "    \n",
    "    return word2vec_tokens\n",
    "\n",
    "\n",
    "# build w2v model\n",
    "startTime = time.time()\n",
    "\n",
    "word2vec_tokens = build_w2v_model(' '.join(df['Clean_text']).lower())\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Building time in sec.: ' + str(executionTime))\n",
    "\n",
    "# Save the model for later use\n",
    "word2vec_tokens.save('french_literature_model.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39320932",
   "metadata": {},
   "source": [
    "# Reduce the language model for the purpose of visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687cf8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlakj\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLove lighting in French Literature\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m french_literature_model \u001b[38;5;241m=\u001b[39m Word2Vec\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrench_literature_model.model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the model\n",
    "french_literature_model = Word2Vec.load('french_literature_model.model')\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    # extract the words & their vectors, as numpy arrays\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(french_literature_model)\n",
    "\n",
    "# Send the x, y, and label values to a dataframe and save it for later use\n",
    "df = pd.DataFrame({'x_vals':x_vals, 'y_vals':y_vals, 'labels':labels})\n",
    "df.to_csv('french_literature_model_values_labels_2D.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90f648-25aa-484e-9ce9-a32fb427cb17",
   "metadata": {},
   "source": [
    "# Load the Gensim model and make an analyse of word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd59ec8-d629-44f6-9477-c6b56719ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Libraries \n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\lakj\\\\Love lighting in French Literature\\\\data')\n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# load the model\n",
    "french_literature_model = Word2Vec.load('french_literature_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b60d243-6180-4d82-917d-32f31a069995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french_literature_model: abattu \n",
      "\n",
      "[('mis', 0.9754560589790344), ('beaucoup', 0.975274384021759), ('payer', 0.9752501845359802), ('somme', 0.9750092625617981), ('but', 0.9748916029930115)]\n",
      "\n",
      "\n",
      "french_literature_model: abruti \n",
      "\n",
      "[('exproprié', 0.39207157492637634), ('verriez', 0.3917907774448395), ('contenterai', 0.3851637542247772), ('avénement', 0.3734688460826874), ('ligure', 0.3702930808067322)]\n",
      "\n",
      "\n",
      "french_literature_model: agonie \n",
      "\n",
      "[('autant', 0.981724202632904), ('elle', 0.9807077050209045), ('effet', 0.9805507063865662), ('eut', 0.980294942855835), ('aucune', 0.9802603125572205)]\n",
      "\n",
      "\n",
      "french_literature_model: aimer \n",
      "\n",
      "[('urbain', 0.9957081079483032), ('tiens', 0.9950606226921082), ('savoir', 0.9946962594985962), ('vérité', 0.9939529895782471), ('ait', 0.993726909160614)]\n",
      "\n",
      "\n",
      "french_literature_model: aimé \n",
      "\n",
      "[('répondit', 0.9970437288284302), ('serait', 0.9968804121017456), ('ah', 0.9967793822288513), (\"qu'il\", 0.9967734217643738), ('comment', 0.9967658519744873)]\n",
      "\n",
      "\n",
      "french_literature_model: amant \n",
      "\n",
      "[('’', 0.9745244979858398), ('oubli', 0.9736059308052063), ('avançait', 0.972428560256958), ('amour', 0.9705737829208374), ('habitude', 0.9697394967079163)]\n",
      "\n",
      "\n",
      "french_literature_model: amour \n",
      "\n",
      "[('idée', 0.9978951811790466), ('maître', 0.997711181640625), ('être', 0.9974576234817505), ('enfant', 0.9961139559745789), ('encore', 0.9957967400550842)]\n",
      "\n",
      "\n",
      "french_literature_model: amoureux \n",
      "\n",
      "[('éloignant', 0.6969591975212097), ('manqué', 0.6776958703994751), ('élevèrent', 0.6709495186805725), ('parvient', 0.6673702597618103), ('parla', 0.6662607789039612)]\n",
      "\n",
      "\n",
      "french_literature_model: attendri \n",
      "\n",
      "[('tenait', 0.9775702357292175), ('laissa', 0.9774265289306641), ('famille', 0.9771296381950378), ('voiture', 0.9771206378936768), ('ensemble', 0.9769564867019653)]\n",
      "\n",
      "\n",
      "french_literature_model: attirant \n",
      "\n",
      "[('extasia', 0.3804263174533844), ('dégagements', 0.3785914480686188), ('manquant', 0.3649875819683075), ('manquerons', 0.36149775981903076), ('hommasse', 0.36076775193214417)]\n",
      "\n",
      "\n",
      "french_literature_model: attrait \n",
      "\n",
      "[('il', 0.8877586126327515), ('cessé', 0.8833334445953369), ('elle', 0.8827878832817078), ('gagner', 0.881527841091156), ('vécu', 0.8812481164932251)]\n",
      "\n",
      "\n",
      "french_literature_model: au bras \n",
      "\n",
      "Term or frase is not present in the model\n",
      "\n",
      "\n",
      "french_literature_model: battement de cœur \n",
      "\n",
      "Term or frase is not present in the model\n",
      "\n",
      "\n",
      "french_literature_model: beauté \n",
      "\n",
      "[('bouche', 0.9968805909156799), ('cour', 0.9966377019882202), ('premières', 0.9949774146080017), ('maladies', 0.994742751121521), ('poitrine', 0.994688868522644)]\n",
      "\n",
      "\n",
      "french_literature_model: bouleverser \n",
      "\n",
      "[('haussaient', 0.3828619122505188), ('tordgueule', 0.37984004616737366), ('impriment', 0.35354483127593994), ('palabretti', 0.35278353095054626), ('funéraires', 0.35115480422973633)]\n",
      "\n",
      "\n",
      "*-**-**-**-**-**-**-**-**-**-*\n",
      "french_literature_model: lumière \n",
      "\n",
      "[('maison', 0.998955488204956), ('du', 0.9988898634910583), ('autour', 0.998817503452301), ('bruit', 0.9988163709640503), ('sous', 0.998753547668457)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open four word lists\n",
    "# 1\n",
    "of = open('emotion_list.txt', 'r', encoding='utf-8-sig')\n",
    "emotion_word_list = of.read().lower().split('\\n')\n",
    "emotion_word_list = [i.strip() for i in emotion_word_list]\n",
    "emotion_word_list.remove('[name of love interest]')\n",
    "emotion_word_list = list(set(emotion_word_list))\n",
    "emotion_word_list.sort()\n",
    "of.close()\n",
    "# 2\n",
    "of = open('lightning_list.txt', 'r', encoding='utf-8-sig')\n",
    "lightning_word_list = of.read().lower().split('\\n')\n",
    "lightning_word_list = [i.strip() for i in lightning_word_list]\n",
    "lightning_word_list = list(set(lightning_word_list))\n",
    "lightning_word_list.sort()\n",
    "of.close()\n",
    "# 3\n",
    "of = open('natural_light_list.txt', 'r', encoding='utf-8-sig')\n",
    "natural_word_list = of.read().lower().split('\\n')\n",
    "natural_word_list = [i.strip() for i in natural_word_list]\n",
    "natural_word_list = list(set(natural_word_list))\n",
    "natural_word_list.sort()\n",
    "of.close()\n",
    "# 4\n",
    "of = open('technology_list.txt', 'r', encoding='utf-8-sig')\n",
    "technology_list = of.read().lower().split('\\n')\n",
    "technology_list = [i.strip() for i in technology_list]\n",
    "technology_list = list(set(technology_list))\n",
    "technology_list.sort()\n",
    "of.close()\n",
    "\n",
    "# Function that can handle a word list and return five similar word for each word in the word list\n",
    "\n",
    "def get_similar_words(word_list, no = 5):\n",
    "    \n",
    "    for term in word_list:\n",
    "        try:\n",
    "\n",
    "            print ('french_literature_model:', term, '\\n')\n",
    "            print (french_literature_model.wv.most_similar(term, topn=no))\n",
    "            print ('\\n')\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            print (\"Term or frase is not present in the model\")\n",
    "            print ('\\n')\n",
    "            \n",
    "\n",
    "#############            \n",
    "# put a wordlist into the function and get words similar to the words in the word list\n",
    "############\n",
    "get_similar_words(emotion_word_list[0:15], no = 5)\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "# If you will look up a single word then \n",
    "# replace the text string after the variable 'term'\n",
    "# and adjust the integer after the variable no to get x amount of simiar words \n",
    "#############\n",
    "print (10 * '*-*')\n",
    "term = 'lumière'\n",
    "no = 5\n",
    "try:\n",
    "    print ('french_literature_model:', term, '\\n')\n",
    "    print (french_literature_model.wv.most_similar(term, topn=no))\n",
    "    print ('\\n')\n",
    "\n",
    "except KeyError:\n",
    "\n",
    "    print (\"Term or frase is not present in the model\")\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9f731-7820-4fe9-89c4-da7d7af8a64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
