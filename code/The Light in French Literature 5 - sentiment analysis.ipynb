{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9bc2ac",
   "metadata": {},
   "source": [
    "Sentiment analysis of sentences holding keywords from emotion and technology lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6375537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ff543d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abattu</td>\n",
       "      <td>gaz</td>\n",
       "      <td>14.0</td>\n",
       "      <td>—il faut faire déchirer ce procès-verbal ajout...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abattu</td>\n",
       "      <td>lustre</td>\n",
       "      <td>14.0</td>\n",
       "      <td>—il faut faire déchirer ce procès-verbal ajout...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abattu</td>\n",
       "      <td>lumière</td>\n",
       "      <td>14.0</td>\n",
       "      <td>—il faut faire déchirer ce procès-verbal ajout...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abattu</td>\n",
       "      <td>flambeau</td>\n",
       "      <td>441.0</td>\n",
       "      <td>—ficelons-nous se dit-elle il faut que le vice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abattu</td>\n",
       "      <td>lampe</td>\n",
       "      <td>441.0</td>\n",
       "      <td>—ficelons-nous se dit-elle il faut que le vice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>voix</td>\n",
       "      <td>bougeoir</td>\n",
       "      <td>441.0</td>\n",
       "      <td>—ficelons-nous se dit-elle il faut que le vice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>voix</td>\n",
       "      <td>lustre</td>\n",
       "      <td>441.0</td>\n",
       "      <td>—ficelons-nous se dit-elle il faut que le vice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>voix</td>\n",
       "      <td>lumière</td>\n",
       "      <td>441.0</td>\n",
       "      <td>—ficelons-nous se dit-elle il faut que le vice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>voix</td>\n",
       "      <td>tige</td>\n",
       "      <td>441.0</td>\n",
       "      <td>—ficelons-nous se dit-elle il faut que le vice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>volupté</td>\n",
       "      <td>lustre</td>\n",
       "      <td>38.0</td>\n",
       "      <td>—l’affaire dite des fourrages à laquelle quelq...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1804 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word1     word2  sentiment_score  \\\n",
       "0      abattu       gaz             14.0   \n",
       "1      abattu    lustre             14.0   \n",
       "2      abattu   lumière             14.0   \n",
       "3      abattu  flambeau            441.0   \n",
       "4      abattu     lampe            441.0   \n",
       "...       ...       ...              ...   \n",
       "1799     voix  bougeoir            441.0   \n",
       "1800     voix    lustre            441.0   \n",
       "1801     voix   lumière            441.0   \n",
       "1802     voix      tige            441.0   \n",
       "1803  volupté    lustre             38.0   \n",
       "\n",
       "                                               sentence sentiment_cat  \n",
       "0     —il faut faire déchirer ce procès-verbal ajout...           pos  \n",
       "1     —il faut faire déchirer ce procès-verbal ajout...           pos  \n",
       "2     —il faut faire déchirer ce procès-verbal ajout...           pos  \n",
       "3     —ficelons-nous se dit-elle il faut que le vice...           pos  \n",
       "4     —ficelons-nous se dit-elle il faut que le vice...           pos  \n",
       "...                                                 ...           ...  \n",
       "1799  —ficelons-nous se dit-elle il faut que le vice...           pos  \n",
       "1800  —ficelons-nous se dit-elle il faut que le vice...           pos  \n",
       "1801  —ficelons-nous se dit-elle il faut que le vice...           pos  \n",
       "1802  —ficelons-nous se dit-elle il faut que le vice...           pos  \n",
       "1803  —l’affaire dite des fourrages à laquelle quelq...           pos  \n",
       "\n",
       "[1804 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "input_dir = Path.cwd() / '../data/csv_files' # input directory\n",
    "df = pd.read_csv(input_dir /'text_data230826.csv', sep='|')\n",
    "\n",
    "\n",
    "# text string input\n",
    "work = 'La Cousine Bette'\n",
    "text = df[df['title'] == work].iloc[0]['clean_text']\n",
    "\n",
    "\n",
    "# split the text in sentences\n",
    "def sent_tokenizer(text):\n",
    "    tokenized_sentences = re.split('\\.', text)\n",
    "    tokenized_sentences = [s.lstrip() for s in tokenized_sentences]\n",
    "    return tokenized_sentences\n",
    "\n",
    "sentence_list = sent_tokenizer(text)\n",
    "\n",
    "\n",
    "#### Read two lists of keywords - technology and emotion keyowrds ####\n",
    "\n",
    "# path to keyword lists directory \n",
    "input_dir = Path.cwd() / '../data/key_word_lists' \n",
    "\n",
    "\n",
    "# get the tech words\n",
    "key_word_file_name = 'technology_list.txt'\n",
    "with open(input_dir / key_word_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "    tech_key_words = file.read().split('\\n')\n",
    "    \n",
    "# get the emo words    \n",
    "key_word_file_name = 'emotion_list.txt'\n",
    "with open(input_dir / key_word_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "    emo_key_words = file.read().split('\\n')\n",
    "    \n",
    "    \n",
    "#####################\n",
    "# add two word lists and run to get a sentiment score\n",
    "####################\n",
    "def sentiment_analysis(word_list1 = emo_key_words, word_list2 = tech_key_words):\n",
    "    \n",
    "    \n",
    "    from_word_list_one = []\n",
    "    from_word_list_two = []\n",
    "    sentiment_scores = []\n",
    "    sentences = []\n",
    "    \n",
    "    for word1 in word_list1:\n",
    "        for sent in sentence_list:\n",
    "            if word1 in sent:\n",
    "                for word2 in word_list2:\n",
    "                    if word2 in sent:\n",
    "                        from_word_list_one.append(word1)\n",
    "                        from_word_list_two.append(word2)\n",
    "                        afinn = Afinn()\n",
    "                        sent_score = afinn.score(str(sent))\n",
    "                        sentiment_scores.append(sent_score)\n",
    "                        sentences.append(sent)\n",
    "    \n",
    "    senti_dataframe = pd.DataFrame({'word1': from_word_list_one, 'word2': from_word_list_two, \n",
    "                                        'sentiment_score': sentiment_scores, 'sentence': sentences})\n",
    "    \n",
    "    return senti_dataframe\n",
    "\n",
    "# add positive, negative, or neutral cetegory\n",
    "def apply_sentiment_cat(row):\n",
    "    if row < 0:\n",
    "        return 'neg'\n",
    "    elif row == 0:\n",
    "        return 'neu'\n",
    "    elif row > 0:\n",
    "        return 'pos'\n",
    "                \n",
    "sentiment_dataframe = sentiment_analysis(emo_key_words, tech_key_words)\n",
    "sentiment_dataframe['sentiment_cat'] = sentiment_dataframe['sentiment_score'].apply(lambda x : apply_sentiment_cat(x) )\n",
    "\n",
    "sentiment_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecaf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
